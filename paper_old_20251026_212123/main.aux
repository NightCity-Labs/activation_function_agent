\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ramachandran2017searching}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Main Contributions}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Key Results Preview}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Paper Structure}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}{section.2}\protected@file@percent }
\newlabel{sec:methods}{{2}{2}{Methods}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Theoretical Framework}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Correlation Objective}{2}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq:signed_objective}{{2}{2}{Correlation Objective}{equation.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Gaussian Mixture Setting}{2}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Mathematical Analysis}{3}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Experimental Setup}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Unit-Level Experiments}{3}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Neural Network Experiments}{3}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Sigma Regime Summary}}{4}{table.1}\protected@file@percent }
\newlabel{tab:sigma_summary}{{1}{4}{Sigma Regime Summary}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{4}{section.3}\protected@file@percent }
\newlabel{sec:results}{{3}{4}{Results}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Unit-Level Findings}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Two-Class Case ($K=2$)}{4}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Multi-Class Case ($K=20$, $\sigma =1.0$)}{4}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Sigma Regime Analysis}{4}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Neural Network Results Summary}}{5}{table.2}\protected@file@percent }
\newlabel{tab:nn_results}{{2}{5}{Neural Network Results Summary}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Analytic vs. Sample Training}{5}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Neural Network Results}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}VGG-11 Backpropagation}{5}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}ResNet-10 Backpropagation}{5}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Layer-Wise Variation}{5}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Histogram Analysis}{5}{subsubsection.3.2.4}\protected@file@percent }
\citation{ramachandran2017searching}
\citation{hendrycks2016gaussian}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Theoretical Validation}{6}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Swish as Optimal Solution}{6}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Backpropagation vs. Correlation}{6}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{6}{section.4}\protected@file@percent }
\newlabel{sec:discussion}{{4}{6}{Discussion}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Why Swish Emerges}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Connection to Existing Activations}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Biological Plausibility}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Limitations}{7}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Theoretical Assumptions}{7}{subsubsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Experimental Scope}{7}{subsubsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Computational Considerations}{7}{subsubsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Future Directions}{7}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Theoretical Extensions}{7}{subsubsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Experimental Directions}{7}{subsubsection.4.5.2}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{hendrycks2016gaussian}{{1}{}{{}}{{}}}
\bibcite{ramachandran2017searching}{{2}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Two-Class Case}: ReLU-like activation emerges for binary classification ($K=2$). Near-zero for negative inputs, linear for positive inputs. The zero-sum constraint creates a threshold detector.}}{8}{figure.1}\protected@file@percent }
\newlabel{fig:two_class}{{1}{8}{\textbf {Two-Class Case}: ReLU-like activation emerges for binary classification ($K=2$). Near-zero for negative inputs, linear for positive inputs. The zero-sum constraint creates a threshold detector}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Multi-Class Case}: Optimal activation function $f(x)$ and class-wise correlations $\rho _k$ for $K=20$ Gaussian mixture ($\sigma =1.0$). Swish-like shape emerges with smooth transition at $x \approx 0$.}}{8}{figure.2}\protected@file@percent }
\newlabel{fig:multi_class}{{2}{8}{\textbf {Multi-Class Case}: Optimal activation function $f(x)$ and class-wise correlations $\rho _k$ for $K=20$ Gaussian mixture ($\sigma =1.0$). Swish-like shape emerges with smooth transition at $x \approx 0$}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Applications}{8}{subsubsection.4.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{8}{section.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{8}{Conclusion}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Sigma Regime Comparison}: Optimal activations across different variance regimes. Small $\sigma $ (0.6): sharp and selective; mid $\sigma $ (1.0): smooth swish; large $\sigma $ (10.0): broad and linear.}}{9}{figure.3}\protected@file@percent }
\newlabel{fig:sigma_regimes}{{3}{9}{\textbf {Sigma Regime Comparison}: Optimal activations across different variance regimes. Small $\sigma $ (0.6): sharp and selective; mid $\sigma $ (1.0): smooth swish; large $\sigma $ (10.0): broad and linear}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Swish Fit Quality}: Learned activation (blue) fitted to swish family (red). Excellent match with $f(x) \approx x \cdot \sigma (2.5x)$ for mid-range $\sigma $.}}{9}{figure.4}\protected@file@percent }
\newlabel{fig:swish_fit}{{4}{9}{\textbf {Swish Fit Quality}: Learned activation (blue) fitted to swish family (red). Excellent match with $f(x) \approx x \cdot \sigma (2.5x)$ for mid-range $\sigma $}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Neural Network Activation Evolution}: Learned activation functions across layers in ResNet-10 after 20 epochs. All layers converge to swish-like shapes with layer-specific parameters. Early layers are broader ($\beta \approx 1.5$), late layers steeper.}}{9}{figure.5}\protected@file@percent }
\newlabel{fig:resnet_activations}{{5}{9}{\textbf {Neural Network Activation Evolution}: Learned activation functions across layers in ResNet-10 after 20 epochs. All layers converge to swish-like shapes with layer-specific parameters. Early layers are broader ($\beta \approx 1.5$), late layers steeper}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Pre-Activation Histograms}: Per-class pre-activation distributions for ResNet-10 layer 0. Approximately Gaussian with separated means, validating theoretical assumptions.}}{9}{figure.6}\protected@file@percent }
\newlabel{fig:histograms}{{6}{9}{\textbf {Pre-Activation Histograms}: Per-class pre-activation distributions for ResNet-10 layer 0. Approximately Gaussian with separated means, validating theoretical assumptions}{figure.6}{}}
\gdef \@abspage@last{9}
